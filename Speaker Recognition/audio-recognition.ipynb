{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport cupy as np # linear algebra\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-16T11:56:52.892602Z","iopub.execute_input":"2022-03-16T11:56:52.893515Z","iopub.status.idle":"2022-03-16T11:56:55.396403Z","shell.execute_reply.started":"2022-03-16T11:56:52.893417Z","shell.execute_reply":"2022-03-16T11:56:55.394993Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!rsync -av /kaggle/input/speaker-recognition-dataset/16000_pcm_speeches train","metadata":{"execution":{"iopub.status.busy":"2022-03-16T11:56:57.756016Z","iopub.execute_input":"2022-03-16T11:56:57.756283Z","iopub.status.idle":"2022-03-16T11:57:37.532647Z","shell.execute_reply.started":"2022-03-16T11:56:57.756254Z","shell.execute_reply":"2022-03-16T11:57:37.531883Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport os\nfrom os.path import isfile, join\nimport numpy as np\nimport shutil\nfrom tensorflow import keras\nfrom pathlib import Path\nfrom IPython.display import display, Audio\nfrom tensorflow.keras.layers import Conv1D\nimport subprocess\nimport numpy","metadata":{"execution":{"iopub.status.busy":"2022-03-16T12:41:02.603740Z","iopub.execute_input":"2022-03-16T12:41:02.604018Z","iopub.status.idle":"2022-03-16T12:41:02.610053Z","shell.execute_reply.started":"2022-03-16T12:41:02.603987Z","shell.execute_reply":"2022-03-16T12:41:02.609289Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"Define Variables","metadata":{}},{"cell_type":"code","source":"dataset = os.path.join( \"train/16000_pcm_speeches\")\n\naudios = 'audio'\nnoises = 'noise'\n\nDATASET_AUDIOS_PATH = os.path.join(dataset, audios)\nDATASET_NOISES_PATH = os.path.join(dataset, noises)\n\n\nVALID_SPLIT = 0.1\n\nSHUFFLE_SEED = 43\n\nSAMPLING_RATE = 16000\n\nSCALE = 0.5\n\nBATCH_SIZE = 128\nEPOCHS = 25","metadata":{"execution":{"iopub.status.busy":"2022-03-16T12:06:45.516171Z","iopub.execute_input":"2022-03-16T12:06:45.516426Z","iopub.status.idle":"2022-03-16T12:06:45.521637Z","shell.execute_reply.started":"2022-03-16T12:06:45.516398Z","shell.execute_reply":"2022-03-16T12:06:45.520968Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"Arrange Audio and Noise","metadata":{}},{"cell_type":"code","source":"if os.path.exists(DATASET_AUDIOS_PATH) is False:\n    os.makedirs(DATASET_AUDIOS_PATH)\n\nif tf.io.gfile.exists(DATASET_NOISES_PATH) is False:\n    tf.io.gfile.makedirs(DATASET_NOISES_PATH)\n\nfor folder in os.listdir(dataset):\n    if os.path.isdir(os.path.join(dataset, folder)):\n        if folder in [audios, noises]:\n            \n            continue\n        elif folder in [\"other\", \"_background_noise_\"]:\n            \n            shutil.move(\n                os.path.join(dataset, folder),\n                os.path.join(DATASET_NOISES_PATH, folder),\n            )\n        else:\n            shutil.move(\n                os.path.join(dataset, folder),\n                os.path.join(DATASET_AUDIOS_PATH, folder),\n            )","metadata":{"execution":{"iopub.status.busy":"2022-03-16T11:58:37.440579Z","iopub.execute_input":"2022-03-16T11:58:37.440842Z","iopub.status.idle":"2022-03-16T11:58:37.451508Z","shell.execute_reply.started":"2022-03-16T11:58:37.440811Z","shell.execute_reply":"2022-03-16T11:58:37.450803Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"noise_paths = []\nfor subdir in tf.io.gfile.listdir(DATASET_NOISES_PATH):\n    subdir_path = Path(DATASET_NOISES_PATH) / subdir\n    if os.path.isdir(subdir_path):\n        noise_paths += [\n            os.path.join(subdir_path, filepath)\n            for filepath in os.listdir(subdir_path)\n            if filepath.endswith(\".wav\")\n        ]\n\nprint(\n    \"Found {} files belonging to {} directories\".format(\n        len(noise_paths), len(os.listdir(DATASET_NOISES_PATH))\n    )\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T11:58:40.229900Z","iopub.execute_input":"2022-03-16T11:58:40.230473Z","iopub.status.idle":"2022-03-16T11:58:40.238979Z","shell.execute_reply.started":"2022-03-16T11:58:40.230434Z","shell.execute_reply":"2022-03-16T11:58:40.238058Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Convert all Noises to 16000HZ","metadata":{}},{"cell_type":"code","source":"command = (\n    \"for dir in `ls -1 \" + DATASET_NOISES_PATH + \"`; do \"\n    \"for file in `ls -1 \" + DATASET_NOISES_PATH + \"/$dir/*.wav`; do \"\n    \"sample_rate=`ffprobe -hide_banner -loglevel panic -show_streams \"\n    \"$file | grep sample_rate | cut -f2 -d=`; \"\n    \"if [ $sample_rate -ne 16000 ]; then \"\n    \"ffmpeg -hide_banner -loglevel panic -y \"\n    \"-i $file -ar 16000 temp.wav; \"\n    \"mv temp.wav $file; \"\n    \"fi; done; done\"\n)\n\nos.system(command)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T11:58:46.250290Z","iopub.execute_input":"2022-03-16T11:58:46.251021Z","iopub.status.idle":"2022-03-16T11:58:47.638021Z","shell.execute_reply.started":"2022-03-16T11:58:46.250968Z","shell.execute_reply":"2022-03-16T11:58:47.637307Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Split noise into chunks of 16000 each","metadata":{}},{"cell_type":"code","source":"def load_noise_sample(path):\n    sample, sampling_rate = tf.audio.decode_wav(\n        tf.io.read_file(path), desired_channels=1\n    )\n    if sampling_rate == SAMPLING_RATE:\n        slices = int(sample.shape[0] / SAMPLING_RATE)\n        sample = tf.split(sample[: slices * SAMPLING_RATE], slices)\n        return sample\n    else:\n        print(\"Sampling rate for {} is incorrect. Ignoring it\".format(path))\n        return None","metadata":{"execution":{"iopub.status.busy":"2022-03-16T11:58:50.212887Z","iopub.execute_input":"2022-03-16T11:58:50.213452Z","iopub.status.idle":"2022-03-16T11:58:50.219145Z","shell.execute_reply.started":"2022-03-16T11:58:50.213416Z","shell.execute_reply":"2022-03-16T11:58:50.218429Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"noises = []\nfor path in noise_paths:\n    sample = load_noise_sample(path)\n    if sample:\n        noises.extend(sample)\nnoises = tf.stack(noises)\n\nprint(\n    \"{} noise files were split into {} noise samples where each is {} sec. long\".format(\n        len(noise_paths), noises.shape[0], noises.shape[1] // SAMPLING_RATE\n    )\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T11:58:53.163438Z","iopub.execute_input":"2022-03-16T11:58:53.165117Z","iopub.status.idle":"2022-03-16T11:58:55.530114Z","shell.execute_reply.started":"2022-03-16T11:58:53.165066Z","shell.execute_reply":"2022-03-16T11:58:55.529364Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Create Dataset","metadata":{}},{"cell_type":"code","source":"def paths_and_labels_to_dataset(audio_paths, labels):\n    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n    audio_ds = path_ds.map(lambda x : path_to_audio(x))\n    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n    return tf.data.Dataset.zip((audio_ds, label_ds))\n\n\ndef path_to_audio(path):\n    audio = tf.io.read_file(path)\n    audio, _ = tf.audio.decode_wav(audio, 1, SAMPLING_RATE)\n    return audio\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T11:59:06.872581Z","iopub.execute_input":"2022-03-16T11:59:06.872845Z","iopub.status.idle":"2022-03-16T11:59:06.878843Z","shell.execute_reply.started":"2022-03-16T11:59:06.872813Z","shell.execute_reply":"2022-03-16T11:59:06.877872Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Add Noise","metadata":{}},{"cell_type":"code","source":"def add_noise(audio, noises=None, scale=0.5):\n    if noises is not None:\n        tf_rnd = tf.random.uniform(\n            (tf.shape(audio)[0],), 0, noises.shape[0], dtype=tf.int32\n        )\n        noise = tf.gather(noises, tf_rnd, axis=0)\n\n        prop = tf.math.reduce_max(audio, axis=1) / tf.math.reduce_max(noise, axis=1)\n        prop = tf.repeat(tf.expand_dims(prop, axis=1), tf.shape(audio)[1], axis=1)\n\n        audio = audio + noise * prop * scale\n\n    return audio","metadata":{"execution":{"iopub.status.busy":"2022-03-16T11:59:23.544006Z","iopub.execute_input":"2022-03-16T11:59:23.544822Z","iopub.status.idle":"2022-03-16T11:59:23.551995Z","shell.execute_reply.started":"2022-03-16T11:59:23.544777Z","shell.execute_reply":"2022-03-16T11:59:23.551066Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def audio_to_fft(audio):\n    audio = tf.squeeze(audio, axis=-1)\n    fft = tf.signal.fft(\n        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n    )\n    fft = tf.expand_dims(fft, axis=-1)\n\n    return tf.math.abs(fft[:, : (audio.shape[1] // 2), :])","metadata":{"execution":{"iopub.status.busy":"2022-03-16T11:59:25.832536Z","iopub.execute_input":"2022-03-16T11:59:25.833301Z","iopub.status.idle":"2022-03-16T11:59:25.839223Z","shell.execute_reply.started":"2022-03-16T11:59:25.833253Z","shell.execute_reply":"2022-03-16T11:59:25.838173Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class_names = tf.io.gfile.listdir(DATASET_AUDIOS_PATH)\nprint(\"Our class names: {}\".format(class_names,))\n\naudio_paths = []\nlabels = []\n\nfor label, name in enumerate(class_names):\n    print(\"Processing speaker {}\".format(name,))\n    dir_path = Path(DATASET_AUDIOS_PATH) / name\n    speaker_sample_paths = [\n        os.path.join(dir_path, filepath)\n        for filepath in os.listdir(dir_path)\n        if filepath.endswith(\".wav\")\n    ]\n    audio_paths += speaker_sample_paths\n    labels += [label] * len(speaker_sample_paths)\n\nprint(labels)\n\nprint(\n    \"Found {} files belonging to {} classes.\".format(len(audio_paths), len(class_names))\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T11:59:31.120438Z","iopub.execute_input":"2022-03-16T11:59:31.120879Z","iopub.status.idle":"2022-03-16T11:59:31.157709Z","shell.execute_reply.started":"2022-03-16T11:59:31.120844Z","shell.execute_reply":"2022-03-16T11:59:31.156829Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"rng = np.random.RandomState(SHUFFLE_SEED)\nrng.shuffle(audio_paths)\nrng = np.random.RandomState(SHUFFLE_SEED)\nrng.shuffle(labels)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T11:59:33.361945Z","iopub.execute_input":"2022-03-16T11:59:33.362482Z","iopub.status.idle":"2022-03-16T11:59:33.368468Z","shell.execute_reply.started":"2022-03-16T11:59:33.362445Z","shell.execute_reply":"2022-03-16T11:59:33.367663Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Split into training and validation","metadata":{}},{"cell_type":"code","source":"\nnum_val_samples = int(VALID_SPLIT * len(audio_paths))\nprint(\"Using {} files for training.\".format(len(audio_paths) - num_val_samples))\ntrain_audio_paths = audio_paths[:-num_val_samples]\ntrain_labels = labels[:-num_val_samples]\n\nprint(\"Using {} files for validation.\".format(num_val_samples))\nvalid_audio_paths = audio_paths[-num_val_samples:]\nvalid_labels = labels[-num_val_samples:]\n\n\n\n# Create 2 datasets, one for training and the other for validation\ntrain_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\ntrain_ds = train_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n    BATCH_SIZE\n)\n\nvalid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\nvalid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=SHUFFLE_SEED).batch(32)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T12:02:24.294717Z","iopub.execute_input":"2022-03-16T12:02:24.295316Z","iopub.status.idle":"2022-03-16T12:02:24.476056Z","shell.execute_reply.started":"2022-03-16T12:02:24.295275Z","shell.execute_reply":"2022-03-16T12:02:24.475146Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Feature Extraction","metadata":{}},{"cell_type":"code","source":"# Add noise to the training set\ntrain_ds = train_ds.map(\n    lambda x, y: (add_noise(x, noises, scale=SCALE), y),\n    num_parallel_calls=tf.data.experimental.AUTOTUNE,\n)\n\n# Transform audio wave to the frequency domain using `audio_to_fft`\ntrain_ds = train_ds.map(\n    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n)\n\ntrain_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n\nvalid_ds = valid_ds.map(\n    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE\n)\nvalid_ds = valid_ds.prefetch(tf.data.experimental.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T12:02:56.636986Z","iopub.execute_input":"2022-03-16T12:02:56.637643Z","iopub.status.idle":"2022-03-16T12:02:56.930948Z","shell.execute_reply.started":"2022-03-16T12:02:56.637606Z","shell.execute_reply":"2022-03-16T12:02:56.930192Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Create Model ","metadata":{}},{"cell_type":"code","source":"def residual_block(x, filters, conv_num=3, activation='relu'):\n    \n  s = keras.layers.Conv1D(filters, 1, padding='same')(x)\n  x = keras.layers.Conv1D(filters, 3, padding='same')(x)\n  x = keras.layers.Add()([x, s])\n  x = keras.layers.Activation(activation)(x)\n  return keras.layers.MaxPool1D(pool_size=2, strides=2)(x)\n\n\ndef build_model(input_shape, num_classes):\n  inputs = keras.layers.Input(shape=input_shape, name='audio_input')\n  x = residual_block(inputs, 16, 2)\n  x = residual_block(x, 32, 2)\n  x = residual_block(x, 64, 3)\n  x = residual_block(x, 128, 3)\n\n  x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n  x = keras.layers.Flatten()(x)\n  x = keras.layers.Dense(256, activation=\"relu\")(x)\n  x = keras.layers.Dense(128, activation=\"relu\")(x)\n  outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output\")(x)\n\n  return keras.models.Model(inputs=inputs, outputs=outputs)\n\n\nmodel = build_model((SAMPLING_RATE // 2, 1), len(class_names))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T12:03:04.539579Z","iopub.execute_input":"2022-03-16T12:03:04.540289Z","iopub.status.idle":"2022-03-16T12:03:04.718456Z","shell.execute_reply.started":"2022-03-16T12:03:04.540253Z","shell.execute_reply":"2022-03-16T12:03:04.714779Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Compile model and fit","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# CallBacks \ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")  # https://keras.io/api/callbacks/tensorboard/\nmodel_save_filename = \"model.h5\"\nearlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\nmdlcheckpoint_cb = keras.callbacks.ModelCheckpoint( model_save_filename, monitor='val_accuracy', save_best_only=True )","metadata":{"execution":{"iopub.status.busy":"2022-03-16T12:04:45.853191Z","iopub.execute_input":"2022-03-16T12:04:45.853473Z","iopub.status.idle":"2022-03-16T12:04:46.496356Z","shell.execute_reply.started":"2022-03-16T12:04:45.853441Z","shell.execute_reply":"2022-03-16T12:04:46.494532Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_ds,\n    epochs=EPOCHS,\n    validation_data=valid_ds,\n    callbacks=[earlystopping_cb, mdlcheckpoint_cb, tensorboard_callback],\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T12:06:55.865190Z","iopub.execute_input":"2022-03-16T12:06:55.865445Z","iopub.status.idle":"2022-03-16T12:36:57.339599Z","shell.execute_reply.started":"2022-03-16T12:06:55.865417Z","shell.execute_reply":"2022-03-16T12:36:57.338877Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"Accuracy","metadata":{}},{"cell_type":"code","source":"print(\"Accuracy of model:\",model.evaluate(valid_ds))","metadata":{"execution":{"iopub.status.busy":"2022-03-16T12:38:09.850367Z","iopub.execute_input":"2022-03-16T12:38:09.850648Z","iopub.status.idle":"2022-03-16T12:38:20.113337Z","shell.execute_reply.started":"2022-03-16T12:38:09.850618Z","shell.execute_reply":"2022-03-16T12:38:20.112566Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}